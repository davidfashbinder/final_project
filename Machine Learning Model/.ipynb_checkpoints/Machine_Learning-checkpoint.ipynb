{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bibliographic-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making connection to Progress DataBase\n",
    "engine = create_engine('postgresql+psycopg2://postgres:Superman78@127.0.0.1:5432/postgres')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-priest",
   "metadata": {},
   "source": [
    "### Loading Salaries.csv to clean and load into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "engaging-teacher",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Teams.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a5c22da0e6d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_to_Load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Teams.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mteam_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_Load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Teams.csv'"
     ]
    }
   ],
   "source": [
    "data_to_Load = \"Teams.csv\"\n",
    "team_data_df = pd.read_csv(data_to_Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_df.to_sql(name='Teams', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_Load = \"Resources/people.csv\"\n",
    "people_data_df = pd.read_csv(data_to_Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data_df.to_sql(name='Players', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_Load = \"Resources/Salaries.csv\"\n",
    "salary_data_df = pd.read_csv(data_to_Load)\n",
    "#salary_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "salary_data_df.to_sql(name='Salary', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_Load = \"Resources/AwardsPlayers.csv\"\n",
    "awards_data_df = pd.read_csv(data_to_Load)\n",
    "#awards_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "awards_data_df.to_sql(name='Awards', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN and LOAD AllStar\n",
    "data_to_Load = \"Resources/AllStarFull.csv\"\n",
    "allStar_data_df = pd.read_csv(data_to_Load)\n",
    "#allStar_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "allStar_data_df.to_sql(name='AllStar', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN and LOAD Batting\n",
    "data_to_Load = \"Resources/Batting.csv\"\n",
    "batting_data_df = pd.read_csv(data_to_Load)\n",
    "#batting_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "batting_data_df.to_sql(name='Player_Batting', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN and LOAD Pitching\n",
    "data_to_Load = \"Resources/pitching.csv\"\n",
    "pitching_data_df = pd.read_csv(data_to_Load)\n",
    "#pitching_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "pitching_data_df.to_sql(name='Player_Pitching', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN and LOAD Pitching\n",
    "data_to_Load = \"Resources/managers.csv\"\n",
    "managers_data_df = pd.read_csv(data_to_Load)\n",
    "#managers_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "managers_data_df.to_sql(name='Managers', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN and LOAD Fielding\n",
    "data_to_Load = \"Resources/fielding.csv\"\n",
    "fielding_data_df = pd.read_csv(data_to_Load)\n",
    "#fielding_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the csv/dataFrame into the table\n",
    "fielding_data_df.to_sql(name='Fielding', con=engine,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-webcam",
   "metadata": {},
   "source": [
    "### At this point you should be able to refresh the tables in your BaseBall_Projects and see (9) tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-observation",
   "metadata": {},
   "source": [
    "Example for pulling tables into dataFrame below: UnComment to TEST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table(\"Fielding\", engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list awardID \n",
    "awards_data_df.awardID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get count of awardID to see the top 2 and choose those as the baseline\n",
    "awards_data_df.groupby('awardID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the players full names to later create a new column\n",
    "people_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge on playerID and drop columns except name and then salaries \n",
    "awards_batting_df = pd.merge(awards_data_df, batting_data_df,on=[\"playerID\"])\n",
    "awards_batting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_batting_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_people_df = pd.merge(salary_data_df,people_data_df, on=[\"playerID\"])\n",
    "salaries_people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_people_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_data_df=pd.merge(salaries_people_df,awards_batting_df,on=[\"playerID\"])\n",
    "baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_data_df[\"PlayerName\"] = baseball_data_df[\"nameFirst\"]+baseball_data_df[\"nameLast\"]\n",
    "baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_baseball_data_df=baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_baseball_data_df = new_baseball_data_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_baseball_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_baseball_data_df =new_baseball_data_df.drop(['SF','GIDP','SH','HBP','IBB','CS','BB','SB','2B','3B','height','weight','tie','notes','bats','throws'],1)\n",
    "new_baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_baseball_data_df =new_baseball_data_df.drop(['birthMonth','birthDay','birthCountry','birthCity','deathYear','deathMonth','deathDay','nameGiven','debut','finalGame','birthState','nameFirst','nameLast'],1)\n",
    "new_baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_baseball_data_df=new_baseball_data_df.dropna()\n",
    "new_baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the awards available\n",
    "new_baseball_data_df.groupby('awardID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a binary output by filtering the salary data. If the salary is greater than $2,085,634 =1 \n",
    "new_baseball_data_df['salaryRange'] = new_baseball_data_df['salary']\n",
    "new_baseball_data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace salary range column with binary integers\n",
    "new_baseball_data_df['salaryRange'].where(~(new_baseball_data_df.salaryRange < 2085634), other=0, inplace=True)\n",
    "new_baseball_data_df['salaryRange'].where(~(new_baseball_data_df.salaryRange > 2085634), other=1, inplace=True)\n",
    "new_baseball_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting to last 40 years (to get active players)\n",
    "baseball_stats = new_baseball_data_df[new_baseball_data_df.birthYear > 1980.0]\n",
    "baseball_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding our awardID column \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "baseball_stats = new_baseball_data_df.copy()\n",
    "baseball_stats['awardID'] = le.fit_transform(baseball_stats['awardID'])\n",
    "baseball_stats['lgID'] = le.fit_transform(baseball_stats['lgID'])\n",
    "baseball_stats['teamID_x'] = le.fit_transform(baseball_stats['teamID_x'])\n",
    "\n",
    "baseball_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_stats =baseball_stats.drop(['lgID_x','lgID_y','playerID','teamID_y','PlayerName','yearID_x','yearID_y'],1)\n",
    "baseball_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types for each column\n",
    "baseball_stats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = baseball_stats.copy()\n",
    "X = X.drop([\"salaryRange\",\"salary\"], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target set.\n",
    "y = baseball_stats[\"salaryRange\"].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-criterion",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=78, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier. We can tweeak the n_estimators to optimize the model more\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-heart",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform updated datafram to csv.\n",
    "\n",
    "baseball_stats.to_csv(r'baseball_stats.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-affairs",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
